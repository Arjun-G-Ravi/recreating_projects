# AIM
This is me trying to replicate Andrej Karpathy's micro grad.
https://github.com/karpathy/micrograd

# Plan of Action
    1. Create class Value, Add __init__
    2. Add methods __add__, mul, repr, relu
    3. define _backward in the above methods to calculate the gradients.
    4. Define the method backward() for Value class
    5. In a new file, Create classes Neuron, Layer, MLP with the methods init, call, parameters, repr

# More Actions
    6. Add more methods in Value class for more functions

